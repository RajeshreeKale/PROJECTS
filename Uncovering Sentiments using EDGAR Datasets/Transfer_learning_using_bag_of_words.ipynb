{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer learning using bag of words.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7JQ2uYF37CKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Applying Transfer Learning using Bag of words model"
      ]
    },
    {
      "metadata": {
        "id": "md5atbgLTH3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from keras import preprocessing\n",
        "from keras.preprocessing import text,sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-tCm8D88cNU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "loading the dataset"
      ]
    },
    {
      "metadata": {
        "id": "CBdkQr2_ei2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imdbTrainPositive = pickle.load(open('imdbTestPositive.pkl', 'rb'))\n",
        "imdbTestPositive = pickle.load(open('imdbTestPositive.pkl', 'rb'))\n",
        "imdbTrainNegative= pickle.load(open('imdbTrainNegative.pkl', 'rb'))\n",
        "imdbTestNegative = pickle.load(open('imdbTestNegative.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELPrQ3zUfkyN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labTrainPos = [1] * len(imdbTrainPositive)\n",
        "labTrainNeg = [0] * len(imdbTrainNegative)\n",
        "totalTrainData = imdbTrainPositive + imdbTrainNegative\n",
        "TotalTrainlabels = labTrainPos + labTrainNeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQYpA_5vggth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({'Text': totalTrainData, 'Sentiment': TotalTrainlabels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdFL7-behC3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = np.asarray(train_df['Text'])\n",
        "train_labels = np.asarray(train_df['Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHGw8femhH-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=250)\n",
        "tokenizer.fit_on_texts(train_data)\n",
        "x_train = tokenizer.texts_to_matrix(train_data, mode='freq')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N31QC5qAv9km",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Designing"
      ]
    },
    {
      "metadata": {
        "id": "qjhrAREzhLa-",
        "colab_type": "code",
        "outputId": "935b8431-08d3-42f1-fade-cb477f9ccb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "numWords = x_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(50, input_shape=(numWords,), activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, train_labels,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 50)                12550     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 12,601\n",
            "Trainable params: 12,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 3s 143us/step - loss: 0.5966 - acc: 0.6730 - val_loss: 0.7513 - val_acc: 0.4744\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 2s 120us/step - loss: 0.4770 - acc: 0.7864 - val_loss: 0.6758 - val_acc: 0.6196\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 2s 121us/step - loss: 0.4447 - acc: 0.7983 - val_loss: 0.5928 - val_acc: 0.6956\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 2s 120us/step - loss: 0.4372 - acc: 0.8028 - val_loss: 0.6219 - val_acc: 0.6810\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 2s 119us/step - loss: 0.4345 - acc: 0.8037 - val_loss: 0.6922 - val_acc: 0.6400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3sn74wH_NPQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing EDGAR dataset json file"
      ]
    },
    {
      "metadata": {
        "id": "Nwx4Vdzoh49H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_df=pd.read_json(\"cleanedDataset.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8omx1bnRj_yZ",
        "colab_type": "code",
        "outputId": "1486836a-3b06-41e3-ed3a-46966789b418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "json_df['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Neutral     780\n",
              "Positive    608\n",
              "Negative    147\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "1eNrZgDjkCBo",
        "colab_type": "code",
        "outputId": "3e70b383-6949-4e04-fb43-1dae659c1b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "json_df = json_df[json_df['sentiment'] != 'Neutral']\n",
        "json_df['sentiment'] = json_df['sentiment'].apply(lambda x: 0 if x == 'Negative' else 1)\n",
        "train_size = int(len(json_df) * .8)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(json_df) - train_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 604\n",
            "Test size: 151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hCTKnwYmAJ7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Total sentiment count according to category"
      ]
    },
    {
      "metadata": {
        "id": "CitXjt4yyIIL",
        "colab_type": "code",
        "outputId": "cd15c995-c301-4dd6-faa6-25cc8f9dba33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "json_df['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    608\n",
              "0    147\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "pdeRzvaBA_9r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the EDGAR dataset"
      ]
    },
    {
      "metadata": {
        "id": "ut6WcQCckFxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_posts = json_df['text'][:train_size]\n",
        "train_tags = json_df['sentiment'][:train_size]\n",
        "\n",
        "test_posts = json_df['text'][train_size:]\n",
        "test_tags = json_df['sentiment'][train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7U-TGVwskKJj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_lables = json_df['sentiment']\n",
        "json_text = json_df['text']\n",
        "maxlen = 10000\n",
        "tokenizer = Tokenizer()\n",
        "testing_sequences = tokenizer.texts_to_sequences(json_text)\n",
        "testing_sequences = preprocessing.sequence.pad_sequences(testing_sequences, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-shlDGelSmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_words = 256\n",
        "batch_size = 24\n",
        "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G8u5qtyZlptj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenize.fit_on_texts(train_posts) # only fit on train\n",
        "x_train = tokenize.texts_to_matrix(train_posts)\n",
        "x_test = tokenize.texts_to_matrix(test_posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_MrN74AyM75",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing model accuracy on EDGAR dataset"
      ]
    },
    {
      "metadata": {
        "id": "l7KDanfNl62_",
        "colab_type": "code",
        "outputId": "b2daa181-cebd-4337-aafd-1371bfc6ba63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(testing_sequences, json_lables,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test score using EDGAR:', score[0])\n",
        "print('Test accuracy using EDGAR:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "755/755 [==============================] - 0s 116us/step\n",
            "Test score using EDGAR: 2.781882445859593\n",
            "Test accuracy using EDGAR: 0.1947019888865237\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}